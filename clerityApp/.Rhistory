df$age <- as.numeric(df$age)
meanAge= sum(na.omit(df$age))/length(na.omit(df$age))
df$age[is.na(df$age)]=meanAge
summary(df)
df$education[is.na(df$education)]=meanEd
df$education <- as.numeric(df$education)
meanEd= sum(na.omit(df$education))/length(na.omit(df$education))
df$education[is.na(df$education)]=meanEd
df$hours.per.week <- as.numeric(df$hours.per.week)
meanHours= sum(na.omit(df$hours.per.week))/length(na.omit(df$hours.per.week))
df$hours.per.week[is.na(df$hours.per.week)]=meanHours
View(df)
df=df[(df != '?').all(axis=1)]
df=df[(df != '?')]
df=data.frame(df[(df != '?')])
View(df)
df<-read.csv('adult-modified.csv')
head(df)
df$age <- as.numeric(df$age)
meanAge= sum(na.omit(df$age))/length(na.omit(df$age))
df$age[is.na(df$age)]=meanAge
df$education <- as.numeric(df$education)
meanEd= sum(na.omit(df$education))/length(na.omit(df$education))
df$education[is.na(df$education)]=meanEd
df$hours.per.week <- as.numeric(df$hours.per.week)
meanHours= sum(na.omit(df$hours.per.week))/length(na.omit(df$hours.per.week))
df$hours.per.week[is.na(df$hours.per.week)]=meanHours
df[(df == '?'),] = NULL
df[(df == '?')] = NULL
df[,(df == '?')] = NULL
df[(df == '?'),"workclass"] = NULL
df[(df$workclass == '?'),"workclass"] = NULL
df<-df - df[(df$workclass == '?'),]
df<- df[-(df$workclass == '?'),]
d<- df[,(df$workclass == '?')]
df<-read.csv('adult-modified.csv')
head(df)
df$age <- as.numeric(df$age)
meanAge= sum(na.omit(df$age))/length(na.omit(df$age))
df$age[is.na(df$age)]=meanAge
df$education <- as.numeric(df$education)
meanEd= sum(na.omit(df$education))/length(na.omit(df$education))
df$education[is.na(df$education)]=meanEd
df$hours.per.week <- as.numeric(df$hours.per.week)
meanHours= sum(na.omit(df$hours.per.week))/length(na.omit(df$hours.per.week))
df$hours.per.week[is.na(df$hours.per.week)]=meanHours
d<- df[,(df$workclass == '?')]
d<- df[(df$workclass == '?'),]
df<-except(df,d)
d<- df[-(df$workclass == '?'),]
View(d)
d<- df[-c(df$workclass == '?'),]
df<-read.csv('adult-modified.csv')
head(df)
df$age <- as.numeric(df$age)
meanAge= sum(na.omit(df$age))/length(na.omit(df$age))
df$age[is.na(df$age)]=meanAge
df$education <- as.numeric(df$education)
meanEd= sum(na.omit(df$education))/length(na.omit(df$education))
df$education[is.na(df$education)]=meanEd
df$hours.per.week <- as.numeric(df$hours.per.week)
meanHours= sum(na.omit(df$hours.per.week))/length(na.omit(df$hours.per.week))
df$hours.per.week[is.na(df$hours.per.week)]=meanHours
d<- df[(df$workclass == '?'),]
library(dplyr)
df<- anti_join(df,d)
summary(df)
write.csv(df,file="adultData.csv")
d<-df
train <- sample(d, FALSE, 0.8)
test <- except(d, train)
d2 = read.csv('testing')
d1 = read.csv('adultData.csv')
d2 = read.csv('testing')
d2 = read.csv('testing.csv')
setwd("~/")
d2 = read.csv('training.csv')
d3 = anti_join(d1,d2)
write.csv(d3,file="testing.csv")
head(df)
df<-read.csv('Coursetopics.csv')
head(df)
mat<-as.matrix(df[,-1])
df<-read.csv('Coursetopics.csv')
head(df)
mat<-as.matrix(df[,-1])
trans<- as(mat, "transactions")
print(mat)
df<-read.csv('Coursetopics.csv')
head(df)
mat<-as.matrix(df[,-1])
print(mat)
mat
df<-read.csv('Coursetopics.csv')
head(df)
mat<-as.matrix(df[,-1])
trans<- as(mat, "transactions")
trans<- as(mat, "transaction")
df<-read.csv('Coursetopics.csv')
head(df)
mat<-as.matrix(df[,-1])
trans<- as(mat, "transaction")
View(dfSorted2)
describe(df)
df.describe()
df.describe
df<-read.csv('Coursetopics.csv')
head(df)
mat<-as.matrix(df[,-1])
trans<- as(mat, "transactions")
rules <- apriori(mat, parameter=list(supp=.2,conf=.6, target="rules"))
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1])
trans<- as(mats, "transactions")
library(arules)
install.packages("arules")
library(arules)
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1])
trans<- as(mats, "transactions")
inspect(trans)
rules <- apriori(trans, parameter=list(supp=.2,conf=.6, target="rules"))
inspect(head(sort(rules,by="lift"),n=5))
library(arules)
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1])
trans<- as(mats, "transactions")
#inspect(trans)
rules <- apriori(trans, parameter=list(supp=.2,conf=.6, target="rules"))
inspect(head(sort(rules,by="lift"),n=5))
library(arules)
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1])
trans<- as(mats, "transactions")
#inspect(trans)
rules <- apriori(trans, parameter=list(supp=.2,conf=.5, target="rules"))
inspect(head(sort(rules,by="lift"),n=5))
library(arules)
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1])
trans<- as(mats, "transactions")
#inspect(trans)
rules <- apriori(trans, parameter=list(supp=.2,conf=.5, target="rules"))
#inspect(head(sort(rules,by="lift"),n=5))
library(arules)
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1]);
trans<- as(mats, "transactions");
#inspect(trans)
rules <- apriori(trans, parameter=list(supp=.2,conf=.5, target="rules"))
#inspect(head(sort(rules,by="lift"),n=5))
summary(rules)
rules <- apriori(trans, parameter=list(supp=.1,conf=.5, target="rules"))
library(arules)
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1]);
trans<- as(mats, "transactions");
#inspect(trans)
rules <- apriori(trans, parameter=list(supp=.1,conf=.5, target="rules"))
summary(rules)
#inspect(head(sort(rules,by="lift"),n=5))
trans<- as(mats, "transactions");
View(trans)
View(mat)
library(arules)
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1]);
trans<- as(mats, "transactions");
#inspect(trans)
rules <- apriori(trans, parameter=list(supp=.1,conf=.3, target="rules"))
summary(rules)
#inspect(head(sort(rules,by="lift"),n=5))
library(arules)
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1]);
trans<- as(mats, "transactions");
#inspect(trans)
rules <- apriori(trans, parameter=list(supp=.1,conf=.9, target="rules"))
summary(rules)
#inspect(head(sort(rules,by="lift"),n=5))
library(arules)
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1]);
trans<- as(mats, "transactions");
#inspect(trans)
rules <- apriori(trans, parameter=list(supp=.6,conf=.9, target="rules"))
summary(rules)
#inspect(head(sort(rules,by="lift"),n=5))
rules <- apriori(trans, parameter=list(supp=.2,conf=.1, target="rules"))
summary(rules)
print(rules)
head(rules)
inspect(head(sort(rules,by="lift"),n=5))
library(arules)
df<-read.csv('Coursetopics.csv')
head(df)
mats<-as.matrix(df[,-1]);
View(mat)
rules <- apriori(trans, parameter=list(supp=.2,conf=.1, target="rules"))
summary(rules)
inspect(head(sort(rules,by="lift"),n=5))
df<-df[-1,]
mats<-as.matrix(df);
trans<- as(mats, "transactions");
rules <- apriori(trans, parameter=list(supp=.2,conf=.1, target="rules"))
inspect(head(sort(rules,by="lift"),n=5))
df<-df[apply(df,1,function(x)!all(x==0)),]
mats<-as.matrix(df);
trans<- as(mats, "transactions");
rules <- apriori(trans, parameter=list(supp=.2,conf=.1, target="rules"))
inspect(head(sort(rules,by="lift"),n=5))
rules <- apriori(trans, parameter=list(supp=.4,conf=.4, target="rules"))
inspect(head(sort(rules,by="lift"),n=5))
rules <- apriori(trans, parameter=list(supp=.05,conf=.4, target="rules"))
inspect(head(sort(rules,by="lift"),n=5))
rules <- apriori(trans, parameter=list(supp=.05,conf=.1, target="rules"))
inspect(head(sort(rules,by="lift"),n=5))
inspect(head(sort(rules,by="lift"),n=8))
inspect(head(sort(rules,by="lift"),n=5))
inspect(head(sort(rules,by="lift"),n=5))
inspect(head(sort(rules,by="lift"),n=6))
#load dplyr
library(dplyr)
#Example: calculating Euclidean distance
#create a random array of 6 numbers in the range 1~100
xarray <- c(sample(c(1:100),6))
#create distance distribution
xdist <- dist(xarray, method="euclidean")
#coerve into matrix format
xdistmat <- as.matrix(xdist)
#coerce into data fram
xdist.df <- as.data.frame(xdistmat)
#set row and column names
names(xdist.df) <- xarray
row.names(xdist.df) <- xarray
#View distance matrix
xdist.df
################################################################################
# EXERCISE 1: create a similar distance distribution matrix for the first 10 Fibonacci numbers
# note: name the columns as 1 through 10 and don't rename the rows (why?)
################################################################################
xarray <c(0,1,1,2,3,5,8,13,21,34)
xdist<- dist(xarray,method="euclidean")
################################################################################
# EXERCISE 1: create a similar distance distribution matrix for the first 10 Fibonacci numbers
# note: name the columns as 1 through 10 and don't rename the rows (why?)
################################################################################
xarray <-c(0,1,1,2,3,5,8,13,21,34)
xdist<- dist(xarray,method="euclidean")
xdistmat<-as.matrix(xdist)
xdist.df<-as.data.frame(xdistmat, col.names=c(1:10))
xdist.df
#loading data
prop.df <- read.csv("properties.csv")
names(prop.df) <- c("x", "Address", "AreaName", "Price", "Lat", "Lng")
prop1.df <- prop.df[c(1:20),]
View(prop1.df)
#delete rows with Lat & Lng values of -999 (coordinates unavailable)
prop.df <- prop.df %>% filter(Lat != -999)
#viewing data
View(prop.df)
prop.df$Price.norm <- (prop.df$Price - min(prop.df$Price))/(max(prop.df$Price)-min(prop.df$Price))
prop.df$Lat.norm <- (prop.df$Lat - min(prop.df$Lat))/(max(prop.df$Lat)-min(prop.df$Lat))
prop.df$Lng.norm <- (prop.df$Lng - min(prop.df$Lng))/(max(prop.df$Lng)-min(prop.df$Lng))
str(prop.df)
data.df <- prop.df[,-c(1:4,7:9)]
data.norm.df <- prop.df[,-c(1:7)]
View(data.df)
View(data.norm.df)
#create a small sample
set.seed(1)
sample.index <- sample(row.names(data.df),50)
data.sample.df <- data.df[sample.index,]
data.sample.norm.df <- data.norm.df[sample.index,]
View(data.sample.df)
#scatter plot
plot(data.sample.df)
#measure Euclidean distances
d <- dist(data.sample.df, method="euclidean")
d.norm <- dist(data.sample.norm.df, method="euclidean")
d.mat <- as.matrix(d)
d.norm.mat <- as.matrix(d.norm)
d.df <- as.data.frame(d.mat)
d.norm.df <- as.data.frame(d.norm.mat)
View(d.df)
# hierarchical clustering and dundelion plot
# in hclust() set argument method =
# to "ward.D", "single", "complete", "average", "median", or "centroid"
hc1 <- hclust(d, method = "single")
plot(hc1, hang = -1, ann = FALSE)
hc2 <- hclust(d.norm, method = "average")
plot(hc2, hang = -1, ann = FALSE)
#create datasets for clustering analysis. consider geographical location
str(prop.df)
data.df <- prop.df[,-c(1:4,7:9)]
data.norm.df <- prop.df[,-c(1:7)]
View(data.df)
View(data.norm.df)
#create a small sample
set.seed(1)
sample.index <- sample(row.names(data.df),50)
data.sample.df <- data.df[sample.index,]
data.sample.norm.df <- data.norm.df[sample.index,]
#scatter plot
plot(data.sample.df)
#measure Euclidean distances
d <- dist(data.sample.df, method="euclidean")
d.norm <- dist(data.sample.norm.df, method="euclidean")
d.mat <- as.matrix(d)
d.norm.mat <- as.matrix(d.norm)
d.df <- as.data.frame(d.mat)
d.norm.df <- as.data.frame(d.norm.mat)
# hierarchical clustering and dundelion plot
# in hclust() set argument method =
# to "ward.D", "single", "complete", "average", "median", or "centroid"
hc1 <- hclust(d, method = "single")
plot(hc1, hang = -1, ann = FALSE)
hc2 <- hclust(d.norm, method = "average")
plot(hc2, hang = -1, ann = FALSE)
prop.df <-prop.df[prop.df$AreaName == "York Mills"]
prop.df <-prop.df[prop.df$AreaName == "York Mills",]
str(prop.df)
data.df <- prop.df[,-c(1:4,7:9)]
data.norm.df <- prop.df[,-c(1:7)]
#create a small sample
#set.seed(1)
#sample.index <- sample(row.names(data.df),50)
data.sample.df <- data.df
data.sample.norm.df <- data.norm.df
#scatter plot
plot(data.sample.df)
#measure Euclidean distances
d <- dist(data.sample.df, method="euclidean")
d.norm <- dist(data.sample.norm.df, method="euclidean")
d.mat <- as.matrix(d)
d.norm.mat <- as.matrix(d.norm)
d.df <- as.data.frame(d.mat)
d.norm.df <- as.data.frame(d.norm.mat)
# hierarchical clustering and dundelion plot
# in hclust() set argument method =
# to "ward.D", "single", "complete", "average", "median", or "centroid"
hc1 <- hclust(d, method = "single")
plot(hc1, hang = -1, ann = FALSE)
hc2 <- hclust(d.norm, method = "average")
plot(hc2, hang = -1, ann = FALSE)
prop.df<-sort(prop.df$Price)
prop.df <- read.csv("properties.csv")
names(prop.df) <- c("x", "Address", "AreaName", "Price", "Lat", "Lng")
prop1.df <- prop.df[c(1:20),]
View(prop1.df)
#delete rows with Lat & Lng values of -999 (coordinates unavailable)
prop.df <- prop.df %>% filter(Lat != -999)
#viewing data
View(prop.df)
prop.df$Price.norm <- (prop.df$Price - min(prop.df$Price))/(max(prop.df$Price)-min(prop.df$Price))
prop.df$Lat.norm <- (prop.df$Lat - min(prop.df$Lat))/(max(prop.df$Lat)-min(prop.df$Lat))
prop.df$Lng.norm <- (prop.df$Lng - min(prop.df$Lng))/(max(prop.df$Lng)-min(prop.df$Lng))
prop.df<-sort(prop.df$Price)
prop.df<-sort(prop.df$Price, decreasing = TRUE)
prop.df<-sort(prop.df$Price, decreasing = TRUE)
prop.df <- read.csv("properties.csv")
names(prop.df) <- c("x", "Address", "AreaName", "Price", "Lat", "Lng")
prop1.df <- prop.df[c(1:20),]
View(prop1.df)
#delete rows with Lat & Lng values of -999 (coordinates unavailable)
prop.df <- prop.df %>% filter(Lat != -999)
#viewing data
View(prop.df)
prop.df$Price.norm <- (prop.df$Price - min(prop.df$Price))/(max(prop.df$Price)-min(prop.df$Price))
prop.df$Lat.norm <- (prop.df$Lat - min(prop.df$Lat))/(max(prop.df$Lat)-min(prop.df$Lat))
prop.df$Lng.norm <- (prop.df$Lng - min(prop.df$Lng))/(max(prop.df$Lng)-min(prop.df$Lng))
prop.df<-sort(prop.df$Price, decreasing = TRUE)
prop.df<-head(prop.df,30)
prop.df<-prop.df[order(Price)]
prop.df<-prop.df[order('Price')]
prop.df <- read.csv("properties.csv")
names(prop.df) <- c("x", "Address", "AreaName", "Price", "Lat", "Lng")
prop1.df <- prop.df[c(1:20),]
View(prop1.df)
prop.df <- read.csv("properties.csv")
names(prop.df) <- c("x", "Address", "AreaName", "Price", "Lat", "Lng")
prop1.df <- prop.df[c(1:20),]
#View(prop1.df)
#delete rows with Lat & Lng values of -999 (coordinates unavailable)
prop.df <- prop.df %>% filter(Lat != -999)
#viewing data
#View(prop.df)
prop.df$Price.norm <- (prop.df$Price - min(prop.df$Price))/(max(prop.df$Price)-min(prop.df$Price))
prop.df$Lat.norm <- (prop.df$Lat - min(prop.df$Lat))/(max(prop.df$Lat)-min(prop.df$Lat))
prop.df$Lng.norm <- (prop.df$Lng - min(prop.df$Lng))/(max(prop.df$Lng)-min(prop.df$Lng))
prop.df<-prop.df[order('Price')]
prop.df <- read.csv("properties.csv")
names(prop.df) <- c("x", "Address", "AreaName", "Price", "Lat", "Lng")
prop1.df <- prop.df[c(1:20),]
#delete rows with Lat & Lng values of -999 (coordinates unavailable)
prop.df <- prop.df %>% filter(Lat != -999)
prop.df$Price.norm <- (prop.df$Price - min(prop.df$Price))/(max(prop.df$Price)-min(prop.df$Price))
prop.df$Lat.norm <- (prop.df$Lat - min(prop.df$Lat))/(max(prop.df$Lat)-min(prop.df$Lat))
prop.df$Lng.norm <- (prop.df$Lng - min(prop.df$Lng))/(max(prop.df$Lng)-min(prop.df$Lng))
prop.df<-prop.df[order('Price'),]
prop.df <- read.csv("properties.csv")
names(prop.df) <- c("x", "Address", "AreaName", "Price", "Lat", "Lng")
#delete rows with Lat & Lng values of -999 (coordinates unavailable)
prop.df <- prop.df %>% filter(Lat != -999)
prop.df$Price.norm <- (prop.df$Price - min(prop.df$Price))/(max(prop.df$Price)-min(prop.df$Price))
prop.df$Lat.norm <- (prop.df$Lat - min(prop.df$Lat))/(max(prop.df$Lat)-min(prop.df$Lat))
prop.df$Lng.norm <- (prop.df$Lng - min(prop.df$Lng))/(max(prop.df$Lng)-min(prop.df$Lng))
prop.df<-prop.df[order(-Price),]
prop.df<-prop.df[order(-Price),]
prop.df<-prop.df[order(-"Price"),]
prop.df<-prop.df[order(-Price),]
prop.df<-prop.df[order(-prop.df$Price),]
prop.df<-head(prop.df,30)
str(prop.df)
data.df <- prop.df[,-c(1:4,7:9)]
data.norm.df <- prop.df[,-c(1:7)]
#create a small sample
#set.seed(1)
#sample.index <- sample(row.names(data.df),50)
data.sample.df <- data.df
data.sample.norm.df <- data.norm.df
#scatter plot
plot(data.sample.df)
#measure Euclidean distances
d <- dist(data.sample.df, method="euclidean")
d.norm <- dist(data.sample.norm.df, method="euclidean")
d.mat <- as.matrix(d)
d.norm.mat <- as.matrix(d.norm)
d.df <- as.data.frame(d.mat)
d.norm.df <- as.data.frame(d.norm.mat)
#View(d.df)
# hierarchical clustering and dundelion plot
# in hclust() set argument method =
# to "ward.D", "single", "complete", "average", "median", or "centroid"
hc1 <- hclust(d, method = "single")
plot(hc1, hang = -1, ann = FALSE)
hc2 <- hclust(d.norm, method = "average")
plot(hc2, hang = -1, ann = FALSE)
prop.df <- read.csv("properties.csv")
names(prop.df) <- c("x", "Address", "AreaName", "Price", "Lat", "Lng")
#delete rows with Lat & Lng values of -999 (coordinates unavailable)
prop.df <- prop.df %>% filter(Lat != -999)
prop.df$Price.norm <- (prop.df$Price - min(prop.df$Price))/(max(prop.df$Price)-min(prop.df$Price))
prop.df$Lat.norm <- (prop.df$Lat - min(prop.df$Lat))/(max(prop.df$Lat)-min(prop.df$Lat))
prop.df$Lng.norm <- (prop.df$Lng - min(prop.df$Lng))/(max(prop.df$Lng)-min(prop.df$Lng))
data.km.df <- prop.df[,-c(1:6)]
set.seed(2)
km <- kmeans(data.km.df, 6)
# show cluster membership
km$cluster
## centroids
km$centers
## plot an empty scatter plot
plot(c(0), xaxt = 'n', ylab = "", type = "l",
ylim = c(min(km$centers), max(km$centers)), xlim=c(0.7,3))
# label x-axes
axis(1, at=c(1,2,3), labels = names(data.km.df))
# plot centroids
for (i in c(1:6))
lines(km$centers[i,], lty = i, lwd = 2, col = ifelse(i %in% c(1, 3, 5),
"black", "dark grey"))
# name clusters
text(x = 0.8, y = km$centers[, 1], labels = paste("Cluster", c(1:6)))
## distance from centers
dist(km$centers)
setwd("~/GitHub/Cler-it-y/clerityApp")
shiny::runApp()
head(d)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
y=range(fitted)/12 *(1:12)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
